{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled10.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TeOqGdTFSxU8"
      },
      "outputs": [],
      "source": [
        "\n",
        "import cv2 \n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from enum import Enum\n",
        "import os\n",
        "import sklearn\n",
        "from skimage.feature import hog\n",
        "from sklearn import svm\n",
        "import sklearn.neighbors\n",
        "import matplotlib.pyplot as plt\n",
        "from evaluation import *\n",
        "from image_utils import *\n",
        "\n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "import datetime\n",
        "import shutil\n",
        "from skimage.feature import local_binary_pattern\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureExtractors(Enum):\n",
        "    MiniImage = 1\n",
        "    HOG = 2\n",
        "    LBP = 3\n",
        "    CNN = 4\n",
        "\n",
        "def extract_features(method, image):\n",
        "\t'''Switch between Feature extraction Methods'''\n",
        "\n",
        "\timage_representation = []\n",
        "\n",
        "\tif method == FeatureExtractors.MiniImage:\n",
        "\t\timage_representation = extract_mini_image_features(image)\n",
        "\telif method == FeatureExtractors.HOG:\n",
        "\t\timage_representation = extract_hog_features(image)\n",
        "\telif method == FeatureExtractors.LBP:\n",
        "\t\timage_representation = extract_lbp_features(image)\n",
        "\telif method == FeatureExtractors.CNN:\n",
        "\t\timage_representation = prep_for_cnn(image)\n",
        "\t\n",
        "\treturn image_representation\n",
        "\n",
        "def extract_mini_image_features(image,resize_size=(64,64)):\n",
        "    shape = image.shape\n",
        "    if len(shape) > 2:\n",
        "        image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
        "    resized_image = cv2.resize(image,resize_size)\n",
        "    image_representation = resized_image.reshape(resize_size[0]*resize_size[1])\n",
        "    return image_representation\n",
        "  \n",
        "def extract_lbp_features(img):\n",
        "\n",
        "\t\n",
        "\tmeth = 'uniform'\n",
        "\trad = 3\n",
        "\tn_point = 8 * rad\n",
        "\tlbp_img = local_binary_pattern(img, n_point, rad, meth)\n",
        "\tto_return = np.concatenate(lbp_img, axis=0)\n",
        "\treturn to_return\n",
        "\n",
        "\n",
        "def extract_hog_features(img):\n",
        "\thf = hog(img, orientations=10, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=False)\n",
        "\treturn hf"
      ],
      "metadata": {
        "id": "4wzSjqYkTVzU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_training_data(training_positive_dir,trainign_negative_dir,feature_extractor=FeatureExtractors.HOG,target_size=(128,128)):\n",
        "    ''' Function for loading loading training data from positive and negative examples\n",
        "    '''\n",
        "    positive_img_files = sorted(glob(training_positive_dir + '/*'))\n",
        "    negative_img_files = sorted(glob(trainign_negative_dir + '/*'))\n",
        "    positive_img_files = positive_img_files[:5000]\n",
        "    negative_img_files = negative_img_files[:5000]\n",
        "    training_data = []\n",
        "    training_labels = []\n",
        "    \n",
        "    print('##Loading {} positive face images'.format(len(positive_img_files)))\n",
        "    for img in tqdm(positive_img_files, total=len(positive_img_files)):\n",
        "        image = cv2.imread(img)[...,::-1]\n",
        "        image = cv2.resize(image, target_size, cv2.INTER_AREA)\n",
        "        image_representation = extract_features(feature_extractor,image)\n",
        "        training_data.append(image_representation)\n",
        "        training_labels.append(1)\n",
        "    \n",
        "    print('##Loading {} negative face images'.format(len(negative_img_files)))\n",
        "    for img in tqdm(negative_img_files,total=len(negative_img_files)):\n",
        "        image = cv2.imread(img)[...,::-1]\n",
        "        image = cv2.resize(image, target_size, cv2.INTER_AREA)\n",
        "        image_representation = extract_features(feature_extractor,image)\n",
        "        training_data.append(image_representation)\n",
        "        training_labels.append(0)   \n",
        "    \n",
        "    training_data = np.asarray(training_data)\n",
        "    training_labels = np.asarray(training_labels)\n",
        "    return training_data, training_labels\n",
        "\n",
        "\n",
        "\n",
        "def load_validation_data(validation_data_dir):\n",
        "\n",
        "    validation_image_files = sorted(glob(validation_data_dir + '/*.jpg'))\n",
        "    val_images = []\n",
        "    \n",
        "    validation_annotations= pd.read_csv(os.path.join(validation_data_dir,'validation_bbox.csv'))\n",
        "    \n",
        "    print(validation_annotations.shape)\n",
        "    validation_bboxes = []\n",
        "    for img_file in tqdm(validation_image_files,total=len(validation_image_files)):\n",
        "        image = cv2.imread(img_file,cv2.IMREAD_COLOR)\n",
        "        val_images.append(image)\n",
        "        image_name = os.path.basename(img_file)\n",
        "        bbox_info = validation_annotations.loc[validation_annotations[\"image_id\"]==image_name]\n",
        "        bbox = np.array([bbox_info['x_left'].values[0],bbox_info['y_top'].values[0],bbox_info['x_left'].values[0]+bbox_info['width'].values[0],bbox_info['y_top'].values[0]+bbox_info['height'].values[0]])\n",
        "        validation_bboxes.append(bbox)\n",
        "        \n",
        "    return val_images, validation_bboxes\n",
        "\n",
        "\n",
        "\n",
        "def show_image_with_bbox(image,bboxes,gt_bbox,draw_GT=True):\n",
        "    if draw_GT: \n",
        "        cv2.rectangle(image, (gt_bbox[0],gt_bbox[1]), (gt_bbox[2],gt_bbox[3]), (0, 0, 255), 2)\n",
        "\n",
        "    for bbox in bboxes:\n",
        "        if len(bbox) == 4:   \n",
        "            top_left = (int(bbox[0]),int(bbox[1]))\n",
        "            bottom_right = (int(bbox[0])+ int(bbox[2]),int(bbox[1])+int(bbox[3]))\n",
        "            cv2.rectangle(image, top_left, bottom_right, (255, 0, 0), 2)\n",
        "\n",
        "    plt.imshow(image[...,::-1])\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Ukfr173ATX4n"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def total_windows(img, window_size, step_size):\n",
        "    [i_rows, i_cols] = img.shape;\n",
        "    w_rows = window_size[1];\n",
        "    w_cols = window_size[0];\n",
        "    \n",
        "    cc = (i_cols + step_size - w_cols)/step_size\n",
        "    cr = (i_rows + step_size - w_rows)/step_size\n",
        "    return int(cc*cr)\n",
        "\n",
        "def sliding_window(img, window_size, scale, step_size):\n",
        "    \n",
        "    scales = [3*(scale/4)]#, 2*(scale/3)]\n",
        "    images = []\n",
        "    \n",
        "    ct = 0\n",
        "    \n",
        "    for s in scales:\n",
        "        width = int(img.shape[1]*s)\n",
        "        heigh = int(img.shape[0]*s)\n",
        "        \n",
        "        image = cv2.resize(img, (width, heigh),\n",
        "                           interpolation = cv2.INTER_AREA)\n",
        "        \n",
        "        if (image.shape[0] < window_size[0] or image.shape[1] < window_size[1]):\n",
        "            break\n",
        "        \n",
        "        images.append(image)\n",
        "        ct += total_windows(image, window_size, step_size)\n",
        "       \n",
        "    patches = np.zeros((window_size[0], window_size[1], ct))\n",
        "    bbox_locations = np.zeros((ct, 4))\n",
        "\n",
        "    i=0\n",
        "    err = 0\n",
        "    for image in images:\n",
        "        for y in range(0, image.shape[0], step_size):\n",
        "            for x in range(0, image.shape[1], step_size):\n",
        "                try:\n",
        "                    patches[:,:,i] = image[y:y+window_size[0], x:x+window_size[1]]\n",
        "                    bbox_locations[i,:] = [int(x*(float(img.shape[1])/float(image.shape[1]))), \n",
        "                                           int(y*(float(img.shape[0])/float(image.shape[0]))),\n",
        "                                           int(window_size[0]*(float(img.shape[0])/float(image.shape[0]))),\n",
        "                                           int(window_size[1]*(float(img.shape[1])/float(image.shape[1])))]\n",
        "                    i+= 1\n",
        "                except:\n",
        "                    if i >= ct:\n",
        "                        err += 1\n",
        "    print('i: ', i, 't: ', ct, 'err: ', err)\n",
        "    return patches, bbox_locations\n"
      ],
      "metadata": {
        "id": "eECa3mAVTZ_8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir='./'\n",
        "face_detection_dir = os.path.join(data_dir, 'face_detection')\n",
        "training_faces_dir = os.path.join(face_detection_dir,'cropped_faces')\n",
        "negative_examples_training_dir = os.path.join(face_detection_dir,'negative_data')\n",
        "validation_faces_dir = os.path.join(face_detection_dir,'validation')\n",
        "validation_raw_faces_dir = os.path.join(face_detection_dir,'val_raw_images')"
      ],
      "metadata": {
        "id": "CQ7fsJh6Tb8Z"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data, training_labels = load_training_data(training_faces_dir,\n",
        "                                                   negative_examples_training_dir,\n",
        "                                                   FeatureExtractors.HOG)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gO77F6WDTeQa",
        "outputId": "52875037-47d7-47e5-ec2c-b8e2aed9d1e3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##Loading 5000 positive face images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [01:20<00:00, 62.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##Loading 5000 negative face images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [01:08<00:00, 72.54it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svm_classifier = svm.SVC(kernel='linear',\n",
        "                         probability=True)\n",
        "svm_classifier.fit(training_data, training_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1WAniyGTgkX",
        "outputId": "1e8dafa7-1575-47c2-d2e6-43c6f7ae73a3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='linear', probability=True)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(svm_classifier, open('./face_detector_svm', 'wb'))\n"
      ],
      "metadata": {
        "id": "oczRNJD-TiYK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pickle.load(open('./face_detector_svm','rb'))"
      ],
      "metadata": {
        "id": "hfgZ16u7TkJn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_true_positives = []\n",
        "total_real_positives = []\n",
        "total_positive_predictions = []\n",
        "window_size = [128, 128]\n",
        "validation_data, validation_bboxes = load_validation_data(validation_faces_dir)\n",
        "k = 0\n",
        "stride = 8\n",
        "scale = 1\n",
        "\n",
        "for img, gt_bbox in zip(validation_data,validation_bboxes):\n",
        "    gray_image = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
        "    patches, bbox_locations = sliding_window(gray_image,window_size,scale,stride)\n",
        "    \n",
        "    ## You need to extract features for every patch (same features you used for training the classifier)\n",
        "    patches_feature_representation = []\n",
        "    for i in range(patches.shape[2]):\n",
        "        patch_representation = extract_features(FeatureExtractors.HOG, patches[:,:,i])\n",
        "        patches_feature_representation.append(patch_representation)\n",
        "    patches_feature_representation = np.asarray(patches_feature_representation)\n",
        "    \n",
        "    ## Get score for each sliding window patch\n",
        "    scores = classifier.predict_proba(patches_feature_representation)  \n",
        "\n",
        "    ## Positive Face Probabilities\n",
        "    face_probabilities = scores[:,1]\n",
        "\n",
        "    [ detected_true_positives, image_real_positives, detected_faces ] = evaluate_detector(bbox_locations, face_probabilities, gt_bbox)\n",
        "    total_true_positives.append(detected_true_positives)\n",
        "    total_real_positives.append(image_real_positives)\n",
        "    total_positive_predictions.append(detected_faces)\n",
        "        \n",
        "total_true_positives = np.asarray(total_true_positives)\n",
        "total_real_positives = np.asarray(total_real_positives)\n",
        "total_positive_predictions = np.asarray(total_positive_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qi-1ee3UTlzP",
        "outputId": "d94353f3-173b-4fde-a897-cdd1ce18327e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(175, 6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 175/175 [00:00<00:00, 307.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i:  308 t:  331 err:  0\n",
            "i:  220 t:  225 err:  0\n",
            "i:  440 t:  469 err:  0\n",
            "i:  45 t:  54 err:  0\n",
            "i:  475 t:  475 err:  616\n",
            "i:  242 t:  247 err:  0\n",
            "i:  295 t:  295 err:  29\n",
            "i:  220 t:  233 err:  0\n",
            "i:  220 t:  225 err:  0\n",
            "i:  264 t:  281 err:  0\n",
            "i:  330 t:  337 err:  0\n",
            "i:  227 t:  227 err:  461\n",
            "i:  396 t:  413 err:  0\n",
            "i:  272 t:  272 err:  492\n",
            "i:  440 t:  466 err:  0\n",
            "i:  440 t:  450 err:  0\n",
            "i:  220 t:  225 err:  0\n",
            "i:  264 t:  275 err:  0\n",
            "i:  198 t:  208 err:  0\n",
            "i:  220 t:  225 err:  0\n",
            "i:  286 t:  306 err:  0\n",
            "i:  220 t:  225 err:  0\n",
            "i:  286 t:  303 err:  0\n",
            "i:  418 t:  447 err:  0\n",
            "i:  198 t:  210 err:  0\n",
            "i:  295 t:  295 err:  29\n",
            "i:  220 t:  225 err:  0\n",
            "i:  330 t:  337 err:  0\n",
            "i:  101 t:  101 err:  24\n",
            "i:  418 t:  438 err:  0\n",
            "i:  286 t:  312 err:  0\n",
            "i:  227 t:  227 err:  461\n",
            "i:  418 t:  438 err:  0\n",
            "i:  317 t:  317 err:  508\n",
            "i:  308 t:  315 err:  0\n",
            "i:  220 t:  225 err:  0\n",
            "i:  198 t:  210 err:  0\n",
            "i:  374 t:  388 err:  0\n",
            "i:  330 t:  337 err:  0\n",
            "i:  352 t:  379 err:  0\n",
            "i:  308 t:  329 err:  0\n",
            "i:  80 t:  88 err:  0\n",
            "i:  264 t:  284 err:  0\n",
            "i:  198 t:  222 err:  0\n",
            "i:  162 t:  165 err:  0\n",
            "i:  308 t:  329 err:  0\n",
            "i:  497 t:  497 err:  25\n",
            "i:  330 t:  337 err:  0\n",
            "i:  308 t:  329 err:  0\n",
            "i:  198 t:  216 err:  0\n",
            "i:  330 t:  345 err:  0\n",
            "i:  80 t:  86 err:  0\n",
            "i:  430 t:  430 err:  26\n",
            "i:  242 t:  261 err:  0\n",
            "i:  418 t:  444 err:  0\n",
            "i:  220 t:  241 err:  0\n",
            "i:  418 t:  433 err:  0\n",
            "i:  362 t:  362 err:  539\n",
            "i:  220 t:  239 err:  0\n",
            "i:  374 t:  388 err:  0\n",
            "i:  220 t:  230 err:  0\n",
            "i:  227 t:  227 err:  461\n",
            "i:  220 t:  225 err:  0\n",
            "i:  330 t:  337 err:  0\n",
            "i:  198 t:  222 err:  0\n",
            "i:  295 t:  295 err:  492\n",
            "i:  198 t:  202 err:  0\n",
            "i:  352 t:  365 err:  0\n",
            "i:  264 t:  284 err:  0\n",
            "i:  220 t:  225 err:  0\n",
            "i:  220 t:  225 err:  0\n",
            "i:  220 t:  225 err:  0\n",
            "i:  286 t:  306 err:  0\n",
            "i:  352 t:  379 err:  0\n",
            "i:  220 t:  225 err:  0\n",
            "i:  176 t:  196 err:  0\n",
            "i:  286 t:  303 err:  0\n",
            "i:  452 t:  452 err:  26\n",
            "i:  286 t:  312 err:  0\n",
            "i:  144 t:  153 err:  0\n",
            "i:  242 t:  267 err:  0\n",
            "i:  198 t:  222 err:  0\n",
            "i:  227 t:  227 err:  461\n",
            "i:  220 t:  225 err:  0\n",
            "i:  63 t:  74 err:  0\n",
            "i:  418 t:  444 err:  0\n",
            "i:  198 t:  222 err:  0\n",
            "i:  295 t:  295 err:  492\n",
            "i:  308 t:  315 err:  0\n",
            "i:  220 t:  236 err:  0\n",
            "i:  220 t:  225 err:  0\n",
            "i:  198 t:  213 err:  0\n",
            "i:  198 t:  222 err:  0\n",
            "i:  242 t:  258 err:  0\n",
            "i:  295 t:  295 err:  29\n",
            "i:  242 t:  261 err:  0\n",
            "i:  462 t:  480 err:  0\n",
            "i:  220 t:  244 err:  0\n",
            "i:  440 t:  466 err:  0\n",
            "i:  220 t:  225 err:  0\n",
            "i:  330 t:  337 err:  0\n",
            "i:  330 t:  337 err:  0\n",
            "i:  176 t:  185 err:  0\n",
            "i:  352 t:  371 err:  0\n",
            "i:  242 t:  264 err:  0\n",
            "i:  308 t:  329 err:  0\n",
            "i:  362 t:  362 err:  539\n",
            "i:  220 t:  225 err:  0\n",
            "i:  220 t:  225 err:  0\n",
            "i:  308 t:  326 err:  0\n",
            "i:  242 t:  264 err:  0\n",
            "i:  396 t:  421 err:  0\n",
            "i:  286 t:  303 err:  0\n",
            "i:  242 t:  261 err:  0\n",
            "i:  308 t:  334 err:  0\n",
            "i:  308 t:  320 err:  0\n",
            "i:  396 t:  405 err:  0\n",
            "i:  295 t:  295 err:  492\n",
            "i:  154 t:  168 err:  0\n",
            "i:  264 t:  275 err:  0\n",
            "i:  80 t:  83 err:  0\n",
            "i:  198 t:  210 err:  0\n",
            "i:  220 t:  225 err:  0\n",
            "i:  198 t:  222 err:  0\n",
            "i:  198 t:  219 err:  0\n",
            "i:  484 t:  506 err:  0\n",
            "i:  220 t:  225 err:  0\n",
            "i:  220 t:  225 err:  0\n",
            "i:  176 t:  188 err:  0\n",
            "i:  198 t:  222 err:  0\n",
            "i:  286 t:  312 err:  0\n",
            "i:  308 t:  329 err:  0\n",
            "i:  198 t:  222 err:  0\n",
            "i:  264 t:  270 err:  0\n",
            "i:  286 t:  303 err:  0\n",
            "i:  220 t:  236 err:  0\n",
            "i:  295 t:  295 err:  492\n",
            "i:  264 t:  275 err:  0\n",
            "i:  27 t:  37 err:  0\n",
            "i:  418 t:  435 err:  0\n",
            "i:  295 t:  295 err:  29\n",
            "i:  330 t:  354 err:  0\n",
            "i:  220 t:  225 err:  0\n",
            "i:  220 t:  225 err:  0\n",
            "i:  484 t:  506 err:  0\n",
            "i:  286 t:  303 err:  0\n",
            "i:  484 t:  506 err:  0\n",
            "i:  132 t:  135 err:  0\n",
            "i:  220 t:  225 err:  0\n",
            "i:  295 t:  295 err:  29\n",
            "i:  440 t:  464 err:  0\n",
            "i:  295 t:  295 err:  29\n",
            "i:  220 t:  225 err:  0\n",
            "i:  220 t:  244 err:  0\n",
            "i:  198 t:  222 err:  0\n",
            "i:  250 t:  250 err:  476\n",
            "i:  220 t:  225 err:  0\n",
            "i:  242 t:  253 err:  0\n",
            "i:  272 t:  272 err:  492\n",
            "i:  242 t:  258 err:  0\n",
            "i:  264 t:  281 err:  0\n",
            "i:  308 t:  326 err:  0\n",
            "i:  220 t:  225 err:  0\n",
            "i:  264 t:  278 err:  0\n",
            "i:  176 t:  180 err:  0\n",
            "i:  352 t:  371 err:  0\n",
            "i:  352 t:  368 err:  0\n",
            "i:  69 t:  69 err:  390\n",
            "i:  242 t:  253 err:  0\n",
            "i:  220 t:  239 err:  0\n",
            "i:  462 t:  492 err:  0\n",
            "i:  378 t:  378 err:  561\n",
            "i:  308 t:  329 err:  0\n",
            "i:  242 t:  253 err:  0\n",
            "i:  220 t:  225 err:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision, recall = precision_and_recall(total_true_positives, total_real_positives,total_positive_predictions)"
      ],
      "metadata": {
        "id": "Ul7ZGtegTn-i"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(recall, precision)\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.xlim(0,1.1)\n",
        "plt.ylim(0,1.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "Af3bFt5vTpOL",
        "outputId": "de9a81a0-3b23-4fdb-e98c-e28de75770af"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 1.1)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAYeElEQVR4nO3de5gV9Z3n8fenL9Dcb90YhIZGxSDRqNCLxksw6hhwNzJJJq7MkETDxCQjuenkGU1mEmN2JzE+ujvuw4yS9TaZJGqSiYsTohMVQ+IEQxNFBUQJoIIXWkFEuXbz3T9O4XTabvo0dHX1OfV5PU8/fapOndOfouH5UPU79StFBGZmll8VWQcwM7NsuQjMzHLORWBmlnMuAjOznHMRmJnlXFXWAbqrtrY2Ghoaso5hZlZSVqxY8WpE1HX0XMkVQUNDA01NTVnHMDMrKZKe6+w5nxoyM8s5F4GZWc65CMzMcs5FYGaWcy4CM7OccxGYmeWci8DMLOdcBGZmOeciMDPLOReBmVnOuQjMzHLORWBmlnMuAjOznHMRmJnlnIvAzCznUisCSbdK2iLpqU6el6QbJa2T9ISkqWllMTOzzqV5RHA7MPMgz88CJiVflwL/lGIWMzPrRGpFEBFLga0H2WQ28M9RsAwYLmlMWnnMzKxjWY4RjAVeaLO8KVn3DpIuldQkqam5ublXwpmZ5UVJDBZHxMKIaIyIxrq6Du+9bGZmhyjLItgM1LdZHpesMzOzXpRlESwCPpF8euhUYHtEvJRhHjOzXKpK640l/Qg4C6iVtAn4BlANEBE3AYuB84F1wE7gkrSymJlZ51IrgoiY08XzAVyW1s83M7PilMRgsZmZpcdFYGaWcy4CM7OccxGYmeWci8DMLOdcBGZmOeciMDPLOReBmVnOuQjMzHLORWBmlnMuAjOznHMRmJnlnIvAzCznXARmZjnnIjAzyzkXgZlZzrkIzMxyzkVgZpZzLgIzs5xzEZiZ5ZyLwMws51wEZmY55yIwM8s5F4GZWc65CMzMcs5FYGaWcy4CM7OccxGYmeWci8DMLOdcBGZmOeciMDPLuVSLQNJMSWslrZN0ZQfPj5e0RNJjkp6QdH6aeczM7J1SKwJJlcACYBYwBZgjaUq7zf4WuDsiTgYuAv4xrTxmZtaxNI8IpgPrImJ9ROwF7gRmt9smgKHJ42HAiynmMTOzDqRZBGOBF9osb0rWtXU1MFfSJmAx8PmO3kjSpZKaJDU1NzenkdXMLLeyHiyeA9weEeOA84HvS3pHpohYGBGNEdFYV1fX6yHNzMpZmkWwGahvszwuWdfWPOBugIj4LVAD1KaYyczM2kmzCJYDkyRNlNSPwmDwonbbPA+cAyDpOApF4HM/Zt2we18rD6/dknUMK2GpFUFEtADzgfuBNRQ+HbRK0jWSLkg2uwL4tKSVwI+AiyMi0spkVo5ue2QjF9+2nK/97El27W3NOo6VoKo03zwiFlMYBG677uttHq8GTk8zg1m5m3fGRF7fuZebl67ndxu2cuOckzluzNCuX2iWyHqw2MwOU7+qCq46/zi+P286r+/ax+wFj3D7IxvwwbUVy0VgVibOnFTHfV88kzOOqeXqe1fzl3c08dqbe7KOZSXARWBWRkYN7s8tn2zkGx+awq+ffZVZ//BrfvPsq1nHsj7ORWBWZiRxyekTueey0xk6oJq5tzzKtxevYW/L/qyjWR/lIjArU1OOHMq9889gzvTx3Lx0PbMXPMLyjVuzjmV9kIvArIwN6FfJtz9yAgs/Po3tO/fysZt+y5fvepwtb+zOOpr1IS4Csxw47z3v4oErZjD/A8fw8yde4uzrf8W6LTuyjmV9hIvALCcG9qvirz/4bu770pnsbdnPDx59PutI1ke4CMxy5qi6wZxz3GjuXfki+1o9gGwuArNc+sjUcbz65l5+/ayn9jIXgVkuzTi2jpGD+vHT37efENjyyEVglkP9qio4/4R38cDqV9i/31NR5J2LwCynRg+pYU/LflwD5iIwyzkPGJuLwCyn3jtuGAC3/GZDxkksay4Cs5w6692jmXX8u/iHB59lw6tvZR3HMuQiMMuxb17wHvpXVXD9v6/NOoplyEVglmOjh9YwZcxQmnf4vgV55iIwM8s5F4GZ8eaeFs9ImmOp3rzezPq+UYP78eiGrUz/+wcZPaQ/J4wdxnuOHMqUIwvf97buZ+3LO6gd3J/jxgxhSE111pGth7kIzHLuhgtP4uLTtvPk5u2s2lz4vmTtFjq64LhfVQXX/dl7mX3S2N4PaqlxEZjlXE11JdMnjmT6xJFvr9u9r5WnX97B6hffoKpSHPeuobz65h7+6eE/8KW7Hmd981ucOamWSUcMYdgAHyGUOkWU1gXmjY2N0dTUlHUMs1zava+Vz//oMX65+pW3140ZVsNXPvhuPjJ1XIbJrCuSVkREY0fPFXVEIOl04GpgQvIaARERR/VUSDPr+2qqK1n48Wls2raLZ7fs4JlX3uTfV73M5Xev5PmtO/niOZOQlHVM66ZiTw3dAnwZWAG0phfHzPo6SdSPHEj9yIGcPfkIPnX6RK761yf53w88y4DqSj4z4+isI1o3FVsE2yPiF6kmMbOSdGAAeXdLK9+572kmjBrIzOPHZB3LuqHY6wiWSLpO0vskTT3wlWoyMysZFRXi+o+dyEn1w5n/w8e47ZENlNr4Y54Ve0RwSvK97UBDAGf3bBwzK1U11ZXc8anpXH7XSr5572r2B8w7Y2LWsawIRRVBRHwg7SBmVvqG1lSz8OPTOPXbD7LmpTeyjmNFKurUkKRhkm6Q1JR8XS9pWBGvmylpraR1kq7sZJsLJa2WtErSD7u7A2bWt1RUiOpKz15TSor9bd0K7AAuTL7eAG472AskVQILgFnAFGCOpCnttpkEXAWcHhHvAb7UrfRmZnbYih0jODoiPtpm+ZuSHu/iNdOBdRGxHkDSncBsYHWbbT4NLIiIbQARsaXIPGZm1kOKPSLYJemMAwvJBWa7unjNWOCFNsubknVtHQscK+kRScskzezojSRdeuC0VHNzc5GRzcysGMUeEXwOuCMZFxCwFbi4h37+JOAsYBywVNIJEfF6240iYiGwEApTTPTAzzUzs0Sxnxp6HDhR0tBkuZiPA2wG6tssj0vWtbUJeDQi9gEbJD1DoRiWF5PLzMwO30GLQNLciPgXSZe3Ww9ARNxwkJcvByZJmkihAC4C/rzdNvcAc4DbJNVSOFW0vlt7YGZmh6WrI4JByfch3X3jiGiRNB+4H6gEbo2IVZKuAZoiYlHy3HmSVlOYw+grEfFad3+WmZkduoMWQUTcnHz/5qG8eUQsBha3W/f1No8DuDz5MjOzDBR7Qdl3JQ2VVC3pQUnNkuamHc7MzNJX7MdHz0sGiP8bsBE4BvhKWqHMrPRFwGtv7vHkcyWg2I+PHtjuvwI/jojtvvmEmXVm594Wfvr7Tfz095sYM6yGD514JFfNmuyb1vRRxR4R/Jukp4FpwIOS6oDd6cUys1L2mRlH87Fp47hq1mT2te5n4dL1NL+5J+tY1oliryO4UtJ3KdygplXSWxSmizAze4fPtrlL2eCaKr72s6cKE9dbn9TVdQRnR8RDkj7SZl3bTf41rWBmZtY7ujoimAE8BHyog+cCF4GZWcnr6jqCbyTfL+mdOGZWrv7PQ+s4YewwTjlqJONHDvTAcR9S1BiBpL8HvntgMjhJI4ArIuJv0wxnZqWvYdQgqirE95c99/a6z844mitnTc4wlbWlYj7jK+mxiDi53brfR0Sv38C+sbExmpqaevvHmtlhiAha9gfPvfYW596wFICGUQO57ZLpTKwd1MWrrSdIWhERjR09V+zHRysl9W/zhgOA/gfZ3szsbVLh9pXHjB7Cw399Fv+9sZ6Nr+1k7cs7so5mFF8EP6Bw/cA8SfOAXwJ3pBfLzMpVQ+0gPnlaQ9YxrI1iryO4VtJK4Nxk1bci4v70YpmZWW8pdooJgDVAS0Q8IGmgpCER4eM6M7MSV+zso58GfgLcnKwaS+GmMmZmh6xp41be2tOSdYzcK3aM4DLgdOANgIh4FhidVigzK2/DB1ZTVSH+7282cMa1D7G3ZX/WkXKt2CLYExF7DyxIqsIzh5jZITpy+AD+46qzOXNSLdt27mNPS2vWkXKt2CL4laSvAgMk/QnwY+De9GKZWbkbPaSGGcfWZR3DKL4I/gZoBp4EPkPh9pO+qtjMrAx0+akhSZXAqoiYDHwv/UhmZtabujwiiIhWYK2k8b2Qx8zMelmx1xGMAFZJ+h3w1oGVEXFBKqnMzKzXFFsEf5dqCjMzy0xXdyirAT4LHENhoPiWiPDVH2ZmZaSrMYI7gEYKJTALuD71RGZm1qu6OjU0JSJOAJB0C/C79COZWd746tRsdXVEsO/AA58SMrOeVlNdCcCHFzzCg2teyThNfnV1RHCipDeSx6JwZfEbyeOIiKGppjOzsnZhYz0VEl/92ZPc+NA6zjnuiKwj5dJBjwgiojIihiZfQyKiqs1jl4CZHZZ+VRX8+SnjOWfyaJ7avJ2zrlvCTb/6A8XcQtd6TnfuR2Bmlor5Zx9DQ+0g1rz0Bt/5xdM0bdzGeVOOYPKYIbx33PCs45U9F4GZZe7k8SM4efwIIoJbfrOBa+97mgeSMYNzjzuC4QOrObF+OH960pEMqanOOG35KXbSuUMiaaaktZLWSbryINt9VFJIakwzj5n1bZL4yzOP4smrP8j/+NPjGTOshhe27mTJ01v4u3ue4l+WPZ91xLKU2hFBMlndAuBPgE3AckmLImJ1u+2GAF8EHk0ri5mVlprqSuaeOoG5p04AoHV/cPRXF/sGNilJ84hgOrAuItYnN7W5E5jdwXbfAq4FdqeYxcxKmJLvL23fxfOv7cw0SzlKswjGAi+0Wd6UrHubpKlAfUT8/GBvJOlSSU2Smpqbm3s+qZn1aRIM7FfJnctf4P3XLeHZV3ZkHamspDpGcDCSKoAbgCu62jYiFkZEY0Q01tX5jkZmeSOJ+7/0fv5m5mQAtu/a18UrrDvSLILNQH2b5XHJugOGAMcDD0vaCJwKLPKAsZl1pH7kQE6sHwbA6ztdBD0pzSJYDkySNFFSP+AiYNGBJyNie0TURkRDRDQAy4ALIqIpxUxmVsKmjh/BqEH9+MGjz2UdpaykVgTJ3ETzgfuBNcDdEbFK0jWSfEMbM+u2mupKPnlaA0vWNvOMxwl6TKpjBBGxOCKOjYijI+J/Juu+HhGLOtj2LB8NmFlX5p46gZrqCr63dH3WUcpGZoPFZmaHYuSgfnx06jj+38oX2b2vNes4ZcFFYGYlZ8axdext2c+Tm7dnHaUsuAjMrORMmzACgKaN2zJOUh5cBGZWckYN7s9RdYNo2rg16yhlwUVgZiWpccIIVjy/jf37fe+Cw+UiMLOS1Ngwktd37mP9q29mHaXkuQjMrCQ1JuMEyz1OcNhcBGZWkibWDmLUoH4eMO4BLgIzK0mSmDZhBCue84Dx4XIRmFnJamwYwcbXdtK8Y0/WUUqai8DMSta0CSMBfFRwmFwEZlayjh87lP5VFR4nOEwuAjMrWf2rKjlx3HCWP+ciOBwuAjMradMaRrBq83Z27fUEdIfKRWBmJe2/NIygZX+wctPrWUcpWS4CMytpU8cfmIDOA8aHykVgZiVt+MB+TBo9mCaPExwyF4GZlbzGhpGseM4T0B0qF4GZlbzGCSPYsbuFZ7b4PsaHwkVgZiWvscE3qjkcLgIzK3njRw6kbkh/DxgfIheBmZU8STROGOEB40PkIjCzstDYMJJN23bx8vbdWUcpOS4CMysLB25U0+QJ6LrNRWBmZWHKkUMZUF3pAeND4CIws7JQXVnBSfXDWeFxgm5zEZhZ2WhsGMHql97grT0tWUcpKS4CMysb0yaMoHV/8PgLnoCuO1wEZlY2pk4YgeQLy7rLRWBmZWNoTTXvPmKIPznUTakWgaSZktZKWifpyg6ev1zSaklPSHpQ0oQ085hZ+WtsGMFjz79OqyegK1pqRSCpElgAzAKmAHMkTWm32WNAY0S8F/gJ8N208phZPnzm/Ufz8y+cQYWyTlI60jwimA6si4j1EbEXuBOY3XaDiFgSETuTxWXAuBTzmFkO1I8cyIRRg5DcBMVKswjGAi+0Wd6UrOvMPOAXHT0h6VJJTZKampubezCimZn1icFiSXOBRuC6jp6PiIUR0RgRjXV1db0bzsyszFWl+N6bgfo2y+OSdX9E0rnA14AZEbEnxTxmZtaBNI8IlgOTJE2U1A+4CFjUdgNJJwM3AxdExJYUs5iZWSdSK4KIaAHmA/cDa4C7I2KVpGskXZBsdh0wGPixpMclLerk7czMLCVpnhoiIhYDi9ut+3qbx+em+fPNzKxrfWKw2MzMsuMiMDPLOReBmVnOuQjMzHLORWBmlnMuAjOznHMRmJnlnIvAzCznXARmZjnnIjAzyzkXgZlZzrkIzMxyzkVgZpZzLgIzs5xzEZiZ5ZyLwMws51wEZmY55yIwM8s5F4GZWc65CMzMcs5FYGaWcy4CM7OccxGYmeWci8DMLOdcBGZmOeciMDPLOReBmVnOuQjMzHLORWBmlnMuAjOznHMRmJnlXKpFIGmmpLWS1km6soPn+0u6K3n+UUkNaeYxM7N3Sq0IJFUCC4BZwBRgjqQp7TabB2yLiGOA/wVcm1YeMzPrWJpHBNOBdRGxPiL2AncCs9ttMxu4I3n8E+AcSUoxk5mZtVOV4nuPBV5os7wJOKWzbSKiRdJ2YBTwatuNJF0KXJos7pH0VCqJ+65a2v2Z5ID3OR/yts9Z7u+Ezp5Iswh6TEQsBBYCSGqKiMaMI/Uq73M+eJ/LX1/d3zRPDW0G6tssj0vWdbiNpCpgGPBaipnMzKydNItgOTBJ0kRJ/YCLgEXttlkEfDJ5/GfAQxERKWYyM7N2Ujs1lJzznw/cD1QCt0bEKknXAE0RsQi4Bfi+pHXAVgpl0ZWFaWXuw7zP+eB9Ln99cn/l/4CbmeWbryw2M8s5F4GZWc712SLI4/QURezz5ZJWS3pC0oOSOv1ccKnoap/bbPdRSSGpz330rjuK2V9JFya/51WSftjbGXtaEX+vx0taIumx5O/2+Vnk7EmSbpW0pbNrnlRwY/Jn8oSkqb2d8Y9ERJ/7ojC4/AfgKKAfsBKY0m6bvwJuSh5fBNyVde5e2OcPAAOTx5/Lwz4n2w0BlgLLgMasc6f8O54EPAaMSJZHZ527F/Z5IfC55PEUYGPWuXtgv98PTAWe6uT584FfAAJOBR7NMm9fPSLI4/QUXe5zRCyJiJ3J4jIK12aUsmJ+zwDfojAP1e7eDJeCYvb308CCiNgGEBFbejljTytmnwMYmjweBrzYi/lSERFLKXwSsjOzgX+OgmXAcEljeifdO/XVIuhoeoqxnW0TES3AgekpSlUx+9zWPAr/oyhlXe5zcshcHxE/781gKSnmd3wscKykRyQtkzSz19Klo5h9vhqYK2kTsBj4fO9Ey1R3/72nqiSmmLA/Jmku0AjMyDpLmiRVADcAF2ccpTdVUTg9dBaFI76lkk6IiNczTZWuOcDtEXG9pPdRuLbo+IjYn3WwvOirRwR5nJ6imH1G0rnA14ALImJPL2VLS1f7PAQ4HnhY0kYK51IXlfCAcTG/403AoojYFxEbgGcoFEOpKmaf5wF3A0TEb4EaCpOzlbOi/r33lr5aBHmcnqLLfZZ0MnAzhRIo9XPH0MU+R8T2iKiNiIaIaKAwLnJBRDRlE/ewFfP3+h4KRwNIqqVwqmh9b4bsYcXs8/PAOQCSjqNQBM29mrL3LQI+kXx66FRge0S8lFWYPnlqKNKbnqLPKnKfrwMGAz9OxsWfj4gLMgt9mIrc57JR5P7eD5wnaTXQCnwlIkr2SLfIfb4C+J6kL1MYOL64xP9Th6QfUSj02mTs4xtANUBE3ERhLOR8YB2wE7gkm6QFnmLCzCzn+uqpITMz6yUuAjOznHMRmJnlnIvAzCznXARmZjnnIjDrgKRWSY9LekrSvZKG9/D7b0yuE0DSmz353mbd5SIw69iuiDgpIo6ncJ3KZVkHMkuLi8Csa78lmRBM0tGS7pO0QtKvJU1O1h8h6WeSViZfpyXr70m2XSXp0gz3waxTffLKYrO+QlIlhekPbklWLQQ+GxHPSjoF+EfgbOBG4FcR8eHkNYOT7T8VEVslDQCWS/ppKV8pbOXJRWDWsQGSHqdwJLAG+KWkwcBp/OcUHwD9k+9nA58AiIhWCtOiA3xB0oeTx/UUJpBzEVif4iIw69iuiDhJ0kAK8+RcBtwOvB4RJxXzBpLOAs4F3hcROyU9TGFCNbM+xWMEZgeR3BHuCxQmRtsJbJD0MXj7vrMnJps+SOH2oUiqlDSMwtTo25ISmExhGm2zPsdFYNaFiHgMeILCDVT+ApgnaSWwiv+87eIXgQ9IehJYQeHeu/cBVZLWAN+hMI22WZ/j2UfNzHLORwRmZjnnIjAzyzkXgZlZzrkIzMxyzkVgZpZzLgIzs5xzEZiZ5dz/B88AJrmBr6l9AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ap = interpolated_average_precision(recall,precision)\n",
        "print('Detection Average Precision is {}'.format(ap))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjF36vsfTqdq",
        "outputId": "6e2316e3-2d32-464c-ec4b-f82f20daa42d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detection Average Precision is [0.5051895]\n"
          ]
        }
      ]
    }
  ]
}